{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vibrastic\\\\Documents'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mencari directory saat ini\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merubah directory\n",
    "os.chdir('D:\\Folder Pribadi Asisten\\Bagus\\Training')\n",
    "# Merubah directory (beneran)\n",
    "os.chdir('D:/Folder Pribadi Asisten/Bagus/Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from keras.layers import Activation, Dense,Dot,merge, Dropout,Lambda,Permute,Multiply,LSTM, Conv2D, Flatten, MaxPooling2D, LSTM,RepeatVector,Reshape,TimeDistributed,UpSampling1D\n",
    "# import common as com\n",
    "import keras.models\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "# from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 64\n",
    "channels = 1\n",
    "input_dim = 640\n",
    "timesteps = 10\n",
    "n_features = 64\n",
    "lr = 0.001\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "numpyA = np.ones([1,64])\n",
    "\n",
    "def multA(x):\n",
    "    A = K.variable(np.ones([1,64]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# def multa(x)\n",
    "def multA_T(x):\n",
    "    A = K.variable(np.ones([1,10]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# weight_2 = Lambda(lambda x:x*0.2)\n",
    "# weight_gru1 = weight_2(gru1)\n",
    "# output = Lambda(lambda x: K.sum(x, axis=-1))(vec)\n",
    "# model.add(Lambda(multA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------#\n",
    "#   注意力模块\n",
    "#-------------------------------------------#\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, lstm_units)\n",
    "\n",
    "    # (batch_size, time_steps, lstm_units) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Permute((2, 1))(inputs)\n",
    "\n",
    "    # 对最后一维进行全连接\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Dense(10, activation='softmax')(a)\n",
    "\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, time_steps, lstm_units)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "\n",
    "    # 相乘\n",
    "    # 相当于获得每一个step中，每个维度在所有step中的权重\n",
    "    output_attention_mul = Multiply()([inputs,a_probs])\n",
    "#     output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generatoe Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 64)       4160        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 64)       0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 1)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 10, 64)       0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 64)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 10, 64)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 10, 64)       0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 10, 64)       0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 640)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          328192      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            1032        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8)            32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8)            0           batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "\n",
    "h = Reshape((640,))(freq_fnorm)\n",
    "# h= Flatten()(cnn_input)\n",
    "# print(h.shape)\n",
    "h = Dense(512)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(8)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "  \n",
    "g_e = keras.models.Model(inputs=input_layer, outputs=h)\n",
    "\n",
    "\n",
    "g_e.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 8)                 585064    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 640)               328320    \n",
      "=================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "x = g_e(input_layer)\n",
    "\n",
    "\n",
    "y = Dense(128)(x)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(128)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(512)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(input_dim)(y)\n",
    "\n",
    "\n",
    "g = keras.models.Model(inputs=input_layer, outputs=y)\n",
    "\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 64)       4160        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 10, 64)       0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 10)           0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 1)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 10, 64)       0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 64)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 10, 64)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 10, 64)       0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10, 64)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 10, 64)       0           reshape_5[0][0]                  \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 640)          0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          328192      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512)          2048        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 512)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          65792       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          32896       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          16512       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128)          512         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            1032        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "cnn_input = Multiply()([input_layer1,freq_fnorm])\n",
    "\n",
    "z = Reshape((640,))(cnn_input)\n",
    "\n",
    "z = Dense(512)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(8)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "encoder = keras.models.Model(input_layer, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 513,024\n",
      "Trainable params: 510,976\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = Dense(512)(input_layer)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "f = Dense(256)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "feature_extractor = keras.models.Model(input_layer, f)\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdvLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori_feature = feature_extractor(x[0])\n",
    "        gan_feature = feature_extractor(x[1])\n",
    "        return K.mean(K.square(ori_feature - K.mean(gan_feature, axis=0)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class CntLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CntLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(ori - gan))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class EncLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EncLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(g_e(ori) - encoder(gan)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "# model for training\n",
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "gan = g(input_layer) # g(x)\n",
    "\n",
    "adv_loss = AdvLoss(name='adv_loss')([input_layer, gan])\n",
    "cnt_loss = CntLoss(name='cnt_loss')([input_layer, gan])\n",
    "enc_loss = EncLoss(name='enc_loss')([input_layer, gan])\n",
    "\n",
    "gan_trainer = keras.models.Model(input_layer, [adv_loss, cnt_loss, enc_loss])\n",
    "\n",
    "# loss function\n",
    "def loss(yt, yp):\n",
    "    return yp\n",
    "\n",
    "losses = {\n",
    "    'adv_loss': loss,\n",
    "    'cnt_loss': loss,\n",
    "    'enc_loss': loss,\n",
    "}\n",
    "\n",
    "lossWeights = {'cnt_loss': 10.0, 'adv_loss': 1.0, 'enc_loss': 1.0}\n",
    "\n",
    "# compile\n",
    "gan_trainer.compile(optimizer=keras.optimizers.Adam(lr=lr), loss=losses, loss_weights=lossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 640)          1166568     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "adv_loss (AdvLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cnt_loss (CntLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_loss (EncLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_trainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-17a1aef96892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = feature_extractor(input_layer)\n",
    "\n",
    "d = Dense(32)(f)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation('elu')(d)\n",
    "\n",
    "d = layers.Dense(1, activation='sigmoid', name='d_out')(d)    \n",
    "\n",
    "d = keras.models.Model(input_layer, d)\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-958d461f4df4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d.compile(optimizer=keras.optimizers.Adam(lr=lr), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
