{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from keras.layers import Activation, Dense,Dot,merge, Dropout,Lambda,Permute,Multiply,LSTM, Conv2D, Flatten, MaxPooling2D, LSTM,RepeatVector,Reshape,TimeDistributed,UpSampling1D\n",
    "# import common as com\n",
    "import keras.models\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "# from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 64\n",
    "channels = 1\n",
    "input_dim = 640\n",
    "timesteps = 10\n",
    "n_features = 64\n",
    "lr = 0.001\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "numpyA = np.ones([1,64])\n",
    "\n",
    "def multA(x):\n",
    "    A = K.variable(np.ones([1,64]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# def multa(x)\n",
    "def multA_T(x):\n",
    "    A = K.variable(np.ones([1,10]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# weight_2 = Lambda(lambda x:x*0.2)\n",
    "# weight_gru1 = weight_2(gru1)\n",
    "# output = Lambda(lambda x: K.sum(x, axis=-1))(vec)\n",
    "# model.add(Lambda(multA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------#\n",
    "#   注意力模块\n",
    "#-------------------------------------------#\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, lstm_units)\n",
    "\n",
    "    # (batch_size, time_steps, lstm_units) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Permute((2, 1))(inputs)\n",
    "\n",
    "    # 对最后一维进行全连接\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Dense(10, activation='softmax')(a)\n",
    "\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, time_steps, lstm_units)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "\n",
    "    # 相乘\n",
    "    # 相当于获得每一个step中，每个维度在所有step中的权重\n",
    "    output_attention_mul = Multiply()([inputs,a_probs])\n",
    "#     output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 64)       4160        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 64)       0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 10)           0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 1)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 10, 64)       0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 64)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 10, 64)       0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 10, 64)       0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10, 64)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 640)          0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 512)          328192      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512)          2048        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 512)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          131328      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          65792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          32896       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128)          512         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          16512       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            1032        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8)            32          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8)            0           batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "\n",
    "h = Reshape((640,))(freq_fnorm)\n",
    "# h= Flatten()(cnn_input)\n",
    "# print(h.shape)\n",
    "h = Dense(512)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(8)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "  \n",
    "g_e = keras.models.Model(inputs=input_layer, outputs=h)\n",
    "\n",
    "\n",
    "g_e.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 8)                 585064    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 640)               328320    \n",
      "=================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "x = g_e(input_layer)\n",
    "\n",
    "\n",
    "y = Dense(128)(x)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(128)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(512)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(input_dim)(y)\n",
    "\n",
    "\n",
    "g = keras.models.Model(inputs=input_layer, outputs=y)\n",
    "\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 10, 64)       4160        reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 10, 64)       0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 10)           0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 10, 1)        0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 10, 64)       0           reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 10, 64)       0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 10, 64)       0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 10, 64)       0           reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 10, 64)       0           lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 10, 64)       0           reshape_9[0][0]                  \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 640)          0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 512)          328192      reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512)          2048        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 512)          0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          65792       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 256)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          32896       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128)          512         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          16512       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128)          512         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 128)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 8)            1032        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8)            32          dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8)            0           batch_normalization_23[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "cnn_input = Multiply()([input_layer1,freq_fnorm])\n",
    "\n",
    "z = Reshape((640,))(cnn_input)\n",
    "\n",
    "z = Dense(512)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(8)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "encoder = keras.models.Model(input_layer, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 513,024\n",
      "Trainable params: 510,976\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = Dense(512)(input_layer)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "f = Dense(256)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "feature_extractor = keras.models.Model(input_layer, f)\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdvLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori_feature = feature_extractor(x[0])\n",
    "        gan_feature = feature_extractor(x[1])\n",
    "        return K.mean(K.square(ori_feature - K.mean(gan_feature, axis=0)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class CntLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CntLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(ori - gan))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class EncLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EncLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(g_e(ori) - encoder(gan)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "# model for training\n",
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "gan = g(input_layer) # g(x)\n",
    "\n",
    "adv_loss = AdvLoss(name='adv_loss')([input_layer, gan])\n",
    "cnt_loss = CntLoss(name='cnt_loss')([input_layer, gan])\n",
    "enc_loss = EncLoss(name='enc_loss')([input_layer, gan])\n",
    "\n",
    "gan_trainer = keras.models.Model(input_layer, [adv_loss, cnt_loss, enc_loss])\n",
    "\n",
    "# loss function\n",
    "def loss(yt, yp):\n",
    "    return yp\n",
    "\n",
    "losses = {\n",
    "    'adv_loss': loss,\n",
    "    'cnt_loss': loss,\n",
    "    'enc_loss': loss,\n",
    "}\n",
    "\n",
    "lossWeights = {'cnt_loss': 10.0, 'adv_loss': 1.0, 'enc_loss': 1.0}\n",
    "\n",
    "# compile\n",
    "gan_trainer.compile(optimizer=keras.optimizers.Adam(lr=lr), loss=losses, loss_weights=lossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 640)          1166568     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "adv_loss (AdvLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cnt_loss (CntLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_loss (EncLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_trainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 128)               513024    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "d_out (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 517,313\n",
      "Trainable params: 515,201\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = feature_extractor(input_layer)\n",
    "\n",
    "d = Dense(32)(f)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation('elu')(d)\n",
    "\n",
    "d = layers.Dense(1, activation='sigmoid', name='d_out')(d)    \n",
    "\n",
    "d = keras.models.Model(input_layer, d)\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.compile(optimizer=keras.optimizers.Adam(lr=lr), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3009/3009 [00:38<00:00, 78.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(914736, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:22<00:00,  7.26it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-b2e6c65b3761>\", line 102, in <module>\n",
      "    x_test = data1.reshape(data1.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
      "ValueError: cannot reshape array of size 116736000 into shape (182400,64,128,1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 116736000 into shape (182400,64,128,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from keras.datasets import mnist\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "# additional\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "n_mels=64\n",
    "n_frames= 10\n",
    "n_hop_frames= 1\n",
    "n_fft= 1024\n",
    "hop_length= 512\n",
    "power= 2.0\n",
    "in_dir_c = 'D:/Folder Pribadi Asisten/Bagus/Training/fan/train/'\n",
    "wav_list_c = os.listdir(in_dir_c)\n",
    "idx = 0\n",
    "\n",
    "for  wav_file_c in tqdm(wav_list_c):     \n",
    "    if wav_file_c.endswith('.wav'):\n",
    "        indir_c1 = in_dir_c + wav_file_c\n",
    "        dims = n_mels * n_frames\n",
    "        y, sr = librosa.load(indir_c1, sr=None, mono=True)\n",
    "#         y -= np.mean(y)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(np.maximum(mel_spectrogram, sys.float_info.epsilon))#(128, 313)\n",
    "#         log_mel_spectrogram = np.abs(log_mel_spectrogram)\n",
    "#         log_mel_spectrogram = np.mean(log_mel_spectrogram, axis=-1)\n",
    "        \n",
    "        n_vectors = len(log_mel_spectrogram[0, :]) - n_frames + 1\n",
    "#         print(n_vectors)\n",
    "        if n_vectors < 1:\n",
    "            vectors = np.empty((0, dims))\n",
    "        vectors = np.zeros((n_vectors, dims))#(250, 8192)\n",
    "        for t in range(n_frames):\n",
    "            vectors[:, n_mels * t : n_mels * (t + 1)] = log_mel_spectrogram[:, t : t + n_vectors].T\n",
    "        vectors = vectors[: : n_hop_frames, :]\n",
    "        if idx == 0:\n",
    "            data = np.zeros((len(wav_list_c) * vectors.shape[0], dims), float)\n",
    "        data[vectors.shape[0] * idx : vectors.shape[0] * (idx + 1), :] = vectors#(752250, 8192)\n",
    "        idx = 1+idx\n",
    "        \n",
    "        #print(data[0].shape)\n",
    "#x_ok = data.reshape(data.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
    "x_ok = data\n",
    "print(x_ok.shape)\n",
    "\n",
    "i=0\n",
    "image = np.reshape(x_ok[i:i+1], (64, 10))\n",
    "\n",
    "# image = image * 127 + 127\n",
    "plt.imshow(image)  \n",
    "\n",
    "\n",
    "\n",
    "in_dir_c1 = 'D:/Folder Pribadi Asisten/Bagus/Training/fan/source_test/'\n",
    "wav_list_c1 = os.listdir(in_dir_c1)\n",
    "y_test = []\n",
    "idx = 0\n",
    "for wav_file_c in tqdm(wav_list_c1):    \n",
    "    if wav_file_c.endswith('.wav'):\n",
    "#         print(wav_file_c.split('_')[4])\n",
    "        if wav_file_c.split('_')[4] == 'anomaly':\n",
    "            for i in range(309):\n",
    "                y_test.append(0)\n",
    "        else :\n",
    "            for i in range(309):\n",
    "                y_test.append(1)\n",
    "        indir_c1 = in_dir_c1 + wav_file_c\n",
    "        dims = n_mels * n_frames\n",
    "        y, sr = librosa.load(indir_c1, sr=None, mono=True)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(np.maximum(mel_spectrogram, sys.float_info.epsilon))#(128, 313)\n",
    "        n_vectors1 = len(log_mel_spectrogram[0, :]) - n_frames + 1\n",
    "        \n",
    "#         if n_vectors1 < 1:\n",
    "#             vectors1 = np.empty((0, dims))\n",
    "        vectors1 = np.zeros((n_vectors1, dims))#(250, 8192)\n",
    "        for t in range(n_frames):\n",
    "            vectors1[:, n_mels * t : n_mels * (t + 1)] = log_mel_spectrogram[:, t : t + n_vectors1].T\n",
    "        vectors1 = vectors1[: : n_hop_frames, :]\n",
    "        #print(vectors1.shape)\n",
    "        if idx == 0:\n",
    "            data1 = np.zeros((len(wav_list_c1) * vectors1.shape[0], dims), float)\n",
    "        \n",
    "        data1[vectors1.shape[0] * idx : vectors1.shape[0] * (idx + 1), :] = vectors1#(752250, 8192)\n",
    "        idx = 1+idx\n",
    "        \n",
    "x_test = data1.reshape(data1.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
    "x_test = data1\n",
    "x_ok.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 20000\n",
    "bz = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(data, batch_size=32):\n",
    "    datalen = len(data)\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        idxes = np.arange(datalen)\n",
    "        np.random.shuffle(idxes)\n",
    "        cnt += 1\n",
    "        for i in range(int(np.ceil(datalen/batch_size))):\n",
    "            train_x = np.take(data, idxes[i*batch_size: (i+1) * batch_size], axis=0)\n",
    "            y = np.ones(len(train_x))\n",
    "            yield train_x, [y, y, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = get_data_generator(x_ok, bz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-c9e048233df7>\", line 14, in <module>\n",
      "    fake_x = g.predict(x)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3727, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1551, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1591, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable _AnonymousVar80 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar80/class tensorflow::Var does not exist.\n",
      "\t [[node model_2/lambda_6/transpose/ReadVariableOp (defined at C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_8119]\n",
      "\n",
      "Function call stack:\n",
      "keras_scratch_graph\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FailedPreconditionError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": " Error while reading resource variable _AnonymousVar80 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar80/class tensorflow::Var does not exist.\n\t [[node model_2/lambda_6/transpose/ReadVariableOp (defined at C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_8119]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "min = 10000\n",
    "for i in range(niter):\n",
    "    \n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        lr *= 0.9\n",
    "        print(lr)\n",
    "    # get batch x, y ###\n",
    "    x, y = train_data_generator.__next__()\n",
    "        \n",
    "    ### train disciminator ###\n",
    "    d.trainable = True\n",
    "        \n",
    "    fake_x = g.predict(x)\n",
    "#     print(lr)    \n",
    "    d_x = np.concatenate([x, fake_x], axis=0)\n",
    "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
    "        \n",
    "    d_loss = d.train_on_batch(d_x, d_y)\n",
    "\n",
    "    ### train generator ###\n",
    "    \n",
    "    d.trainable = False        \n",
    "    g_loss = gan_trainer.train_on_batch(x, y)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        if(g_loss[2]<min):\n",
    "            min = g_loss[2]\n",
    "            #print(type(g_loss[2]))\n",
    "            print(g_loss[2],min)\n",
    "            g.save(\"model/model_pump.hdf5\")\n",
    "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914736, 640)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
