{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from keras.layers import Activation, Dense,Dot,merge, Dropout,Lambda,Permute,Multiply,LSTM, Conv2D, Flatten, MaxPooling2D, LSTM,RepeatVector,Reshape,TimeDistributed,UpSampling1D\n",
    "# import common as com\n",
    "import keras.models\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "# from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 64\n",
    "channels = 1\n",
    "input_dim = 640\n",
    "timesteps = 10\n",
    "n_features = 64\n",
    "lr = 0.001\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "numpyA = np.ones([1,64])\n",
    "\n",
    "def multA(x):\n",
    "    A = K.variable(np.ones([1,64]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# def multa(x)\n",
    "def multA_T(x):\n",
    "    A = K.variable(np.ones([1,10]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# weight_2 = Lambda(lambda x:x*0.2)\n",
    "# weight_gru1 = weight_2(gru1)\n",
    "# output = Lambda(lambda x: K.sum(x, axis=-1))(vec)\n",
    "# model.add(Lambda(multA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------#\n",
    "#   注意力模块\n",
    "#-------------------------------------------#\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, lstm_units)\n",
    "\n",
    "    # (batch_size, time_steps, lstm_units) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Permute((2, 1))(inputs)\n",
    "\n",
    "    # 对最后一维进行全连接\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Dense(10, activation='softmax')(a)\n",
    "\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, time_steps, lstm_units)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "\n",
    "    # 相乘\n",
    "    # 相当于获得每一个step中，每个维度在所有step中的权重\n",
    "    output_attention_mul = Multiply()([inputs,a_probs])\n",
    "#     output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 64)       4160        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 64)       0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 1)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 10, 64)       0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 64)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 10, 64)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 10, 64)       0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 10, 64)       0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 640)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          328192      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            1032        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8)            32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8)            0           batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "\n",
    "h = Reshape((640,))(freq_fnorm)\n",
    "# h= Flatten()(cnn_input)\n",
    "# print(h.shape)\n",
    "h = Dense(512)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(8)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "  \n",
    "g_e = keras.models.Model(inputs=input_layer, outputs=h)\n",
    "\n",
    "\n",
    "g_e.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 8)                 585064    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 640)               328320    \n",
      "=================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "x = g_e(input_layer)\n",
    "\n",
    "\n",
    "y = Dense(128)(x)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(128)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(512)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(input_dim)(y)\n",
    "\n",
    "\n",
    "g = keras.models.Model(inputs=input_layer, outputs=y)\n",
    "\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 64)       4160        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 10, 64)       0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 10)           0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 1)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 10, 64)       0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 64)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 10, 64)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 10, 64)       0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 10, 64)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 10, 64)       0           reshape_5[0][0]                  \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 640)          0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          328192      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512)          2048        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 512)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          65792       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          32896       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          16512       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128)          512         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            1032        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "cnn_input = Multiply()([input_layer1,freq_fnorm])\n",
    "\n",
    "z = Reshape((640,))(cnn_input)\n",
    "\n",
    "z = Dense(512)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(8)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "encoder = keras.models.Model(input_layer, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 513,024\n",
      "Trainable params: 510,976\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = Dense(512)(input_layer)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "f = Dense(256)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "feature_extractor = keras.models.Model(input_layer, f)\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gan Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdvLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori_feature = feature_extractor(x[0])\n",
    "        gan_feature = feature_extractor(x[1])\n",
    "        return K.mean(K.square(ori_feature - K.mean(gan_feature, axis=0)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class CntLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CntLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(ori - gan))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class EncLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EncLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(g_e(ori) - encoder(gan)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "# model for training\n",
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "gan = g(input_layer) # g(x)\n",
    "\n",
    "adv_loss = AdvLoss(name='adv_loss')([input_layer, gan])\n",
    "cnt_loss = CntLoss(name='cnt_loss')([input_layer, gan])\n",
    "enc_loss = EncLoss(name='enc_loss')([input_layer, gan])\n",
    "\n",
    "gan_trainer = keras.models.Model(input_layer, [adv_loss, cnt_loss, enc_loss])\n",
    "\n",
    "# loss function\n",
    "def loss(yt, yp):\n",
    "    return yp\n",
    "\n",
    "losses = {\n",
    "    'adv_loss': loss,\n",
    "    'cnt_loss': loss,\n",
    "    'enc_loss': loss,\n",
    "}\n",
    "\n",
    "lossWeights = {'cnt_loss': 10.0, 'adv_loss': 1.0, 'enc_loss': 1.0}\n",
    "\n",
    "# compile\n",
    "gan_trainer.compile(optimizer=keras.optimizers.Adam(lr=lr), loss=losses, loss_weights=lossWeights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 640)          1166568     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "adv_loss (AdvLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cnt_loss (CntLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_loss (EncLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_trainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 128)               513024    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "d_out (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 517,313\n",
      "Trainable params: 515,201\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = feature_extractor(input_layer)\n",
    "\n",
    "d = Dense(32)(f)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation('elu')(d)\n",
    "\n",
    "d = layers.Dense(1, activation='sigmoid', name='d_out')(d)    \n",
    "\n",
    "d = keras.models.Model(input_layer, d)\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.compile(optimizer=keras.optimizers.Adam(lr=lr), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/3009 [00:00<?, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-26419edb6c49>\", line 47, in <module>\n",
      "    data = np.zeros((len(wav_list_c) * vectors.shape[0], dims), float)\n",
      "MemoryError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'MemoryError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Vibrastic\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# from keras.datasets import mnist\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "# additional\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "n_mels=64\n",
    "n_frames= 10\n",
    "n_hop_frames= 1\n",
    "n_fft= 1024\n",
    "hop_length= 512\n",
    "power= 2.0\n",
    "in_dir_c = 'D:/Folder Pribadi Asisten/Bagus/Training/pump/train/'\n",
    "wav_list_c = os.listdir(in_dir_c)\n",
    "idx = 0\n",
    "\n",
    "for  wav_file_c in tqdm(wav_list_c):     \n",
    "    if wav_file_c.endswith('.wav'):\n",
    "        indir_c1 = in_dir_c + wav_file_c\n",
    "        dims = n_mels * n_frames\n",
    "        y, sr = librosa.load(indir_c1, sr=None, mono=True)\n",
    "#         y -= np.mean(y)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(np.maximum(mel_spectrogram, sys.float_info.epsilon))#(128, 313)\n",
    "#         log_mel_spectrogram = np.abs(log_mel_spectrogram)\n",
    "#         log_mel_spectrogram = np.mean(log_mel_spectrogram, axis=-1)\n",
    "        \n",
    "        n_vectors = len(log_mel_spectrogram[0, :]) - n_frames + 1\n",
    "#         print(n_vectors)\n",
    "        if n_vectors < 1:\n",
    "            vectors = np.empty((0, dims))\n",
    "        vectors = np.zeros((n_vectors, dims))#(250, 8192)\n",
    "        for t in range(n_frames):\n",
    "            vectors[:, n_mels * t : n_mels * (t + 1)] = log_mel_spectrogram[:, t : t + n_vectors].T\n",
    "        vectors = vectors[: : n_hop_frames, :]\n",
    "        if idx == 0:\n",
    "            data = np.zeros((len(wav_list_c) * vectors.shape[0], dims), float)\n",
    "        data[vectors.shape[0] * idx : vectors.shape[0] * (idx + 1), :] = vectors#(752250, 8192)\n",
    "        idx = 1+idx\n",
    "        \n",
    "        #print(data[0].shape)\n",
    "#x_ok = data.reshape(data.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
    "x_ok = data\n",
    "print(x_ok.shape)\n",
    "\n",
    "\n",
    "image = np.reshape(x_ok[i:i+1], (64, 10))\n",
    "# image = image * 127 + 127\n",
    "plt.imshow(image)  \n",
    "\n",
    "\n",
    "\n",
    "in_dir_c1 = 'D:/Folder Pribadi Asisten/Bagus/Training/valve/source_test/'\n",
    "wav_list_c1 = os.listdir(in_dir_c1)\n",
    "y_test = []\n",
    "idx = 0\n",
    "for wav_file_c in tqdm(wav_list_c1):    \n",
    "    if wav_file_c.endswith('.wav'):\n",
    "#         print(wav_file_c.split('_')[4])\n",
    "        if wav_file_c.split('_')[4] == 'anomaly':\n",
    "            for i in range(309):\n",
    "                y_test.append(0)\n",
    "        else :\n",
    "            for i in range(309):\n",
    "                y_test.append(1)\n",
    "        indir_c1 = in_dir_c1 + wav_file_c\n",
    "        dims = n_mels * n_frames\n",
    "        y, sr = librosa.load(indir_c1, sr=None, mono=True)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(np.maximum(mel_spectrogram, sys.float_info.epsilon))#(128, 313)\n",
    "        n_vectors1 = len(log_mel_spectrogram[0, :]) - n_frames + 1\n",
    "        \n",
    "#         if n_vectors1 < 1:\n",
    "#             vectors1 = np.empty((0, dims))\n",
    "        vectors1 = np.zeros((n_vectors1, dims))#(250, 8192)\n",
    "        for t in range(n_frames):\n",
    "            vectors1[:, n_mels * t : n_mels * (t + 1)] = log_mel_spectrogram[:, t : t + n_vectors1].T\n",
    "        vectors1 = vectors1[: : n_hop_frames, :]\n",
    "        #print(vectors1.shape)\n",
    "        if idx == 0:\n",
    "            data1 = np.zeros((len(wav_list_c1) * vectors1.shape[0], dims), float)\n",
    "        \n",
    "        data1[vectors1.shape[0] * idx : vectors1.shape[0] * (idx + 1), :] = vectors1#(752250, 8192)\n",
    "        idx = 1+idx\n",
    "        \n",
    "x_test = data1.reshape(data1.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
    "x_test = data1\n",
    "x_ok.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(914736, 640)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
